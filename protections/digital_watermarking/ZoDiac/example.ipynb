{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8af4ab9a-a26c-4f4c-aab8-9b4e6a60c779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import yaml\n",
    "import os\n",
    "import logging\n",
    "import shutil\n",
    "import numpy as np\n",
    "from PIL import Image \n",
    "logger = logging.getLogger()\n",
    "handler = logging.StreamHandler()\n",
    "handler.setLevel(logging.INFO)\n",
    "logger.addHandler(handler)\n",
    "\n",
    "import torch\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "from diffusers import DDIMScheduler\n",
    "from datasets import load_dataset\n",
    "from diffusers.utils.torch_utils import randn_tensor\n",
    "\n",
    "from main.wmdiffusion import WMDetectStableDiffusionPipeline\n",
    "from main.wmpatch import GTWatermark, GTWatermarkMulti\n",
    "from main.utils import *\n",
    "from loss.loss import LossProvider\n",
    "from loss.pytorch_ssim import ssim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2748227d-8820-40f5-a794-014d62e3652c",
   "metadata": {},
   "source": [
    "## Necessary Setup for All Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9708dfcc-8389-42cd-bd52-261809b338c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===== Load Config =====\n",
      "{'method': 'ZoDiac', 'save_img': './example/output/', 'model_id': '/data/xunaen/Text-to-image-Copyright/stable-diffusion-1-5', 'gen_seed': 0, 'empty_prompt': True, 'w_type': 'single', 'w_channel': 3, 'w_radius': 10, 'w_seed': 10, 'start_latents': 'init_w', 'iters': 100, 'save_iters': [100], 'loss_weights': [10.0, 0.1, 1.0, 0.0], 'ssim_threshold': 0.92, 'detect_threshold': 0.9}\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'===== Load Config =====')\n",
    "device = torch.device('cuda')\n",
    "with open('./example/config/config.yaml', 'r') as file:\n",
    "    cfgs = yaml.safe_load(file)\n",
    "logging.info(cfgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "accc6ac2-9055-4237-877e-9276f91da074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===== Init Pipeline =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e4e3926c57b4a94bb5c22e012ada2cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "logging.info(f'===== Init Pipeline =====')\n",
    "if cfgs['w_type'] == 'single':\n",
    "    wm_pipe = GTWatermark(device, w_channel=cfgs['w_channel'], w_radius=cfgs['w_radius'], generator=torch.Generator(device).manual_seed(cfgs['w_seed']))\n",
    "elif cfgs['w_type'] == 'multi':\n",
    "    wm_pipe = GTWatermarkMulti(device, w_settings=cfgs['w_settings'], generator=torch.Generator(device).manual_seed(cfgs['w_seed']))\n",
    "\n",
    "scheduler = DDIMScheduler.from_pretrained(cfgs['model_id'], subfolder=\"scheduler\")\n",
    "pipe = WMDetectStableDiffusionPipeline.from_pretrained(cfgs['model_id'], scheduler=scheduler).to(device)\n",
    "pipe.set_progress_bar_config(disable=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f44fa9d0-13b2-4a76-a839-56720c73b9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagename = 'pepper.tiff'\n",
    "gt_img_tensor = get_img_tensor(f'./example/input/{imagename}', device)\n",
    "wm_path = cfgs['save_img']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420e6ef3-2834-488c-a438-c85bd4c6d7cd",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Image Watermarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ef73c981-a5a2-46e1-9447-fb3dd718177e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Get init noise\n",
    "def get_init_latent(img_tensor, pipe, text_embeddings, guidance_scale=1.0):\n",
    "    # DDIM inversion from the given image\n",
    "    img_latents = pipe.get_image_latents(img_tensor, sample=False)\n",
    "    reversed_latents = pipe.forward_diffusion(\n",
    "        latents=img_latents,\n",
    "        text_embeddings=text_embeddings,\n",
    "        guidance_scale=guidance_scale,\n",
    "        num_inference_steps=50,\n",
    "    )\n",
    "    return reversed_latents\n",
    "\n",
    "empty_text_embeddings = pipe.get_text_embedding('')\n",
    "init_latents_approx = get_init_latent(gt_img_tensor, pipe, empty_text_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "914c7cd2-65bc-40e3-8708-d32fdf8eb6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xunaen/anaconda3/envs/zodiac/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/xunaen/anaconda3/envs/zodiac/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: prepare training\n",
    "init_latents = init_latents_approx.detach().clone()\n",
    "init_latents.requires_grad = True\n",
    "optimizer = optim.Adam([init_latents], lr=0.01)\n",
    "scheduler = optim.lr_scheduler.MultiStepLR(optimizer, milestones=[30,80], gamma=0.3) \n",
    "\n",
    "totalLoss = LossProvider(cfgs['loss_weights'], device)\n",
    "loss_lst = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b6ab2f-eade-4819-8f7f-220d58930919",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Step 3: train the init latents\n",
    "for i in range(cfgs['iters']):\n",
    "    logging.info(f'iter {i}:')\n",
    "    init_latents_wm = wm_pipe.inject_watermark(init_latents)\n",
    "    if cfgs['empty_prompt']:\n",
    "        pred_img_tensor = pipe('', guidance_scale=1.0, num_inference_steps=50, output_type='tensor', use_trainable_latents=True, init_latents=init_latents_wm).images\n",
    "    else:\n",
    "        pred_img_tensor = pipe(prompt, num_inference_steps=50, output_type='tensor', use_trainable_latents=True, init_latents=init_latents_wm).images\n",
    "    loss = totalLoss(pred_img_tensor, gt_img_tensor, init_latents_wm, wm_pipe)\n",
    "    \n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    loss_lst.append(loss.item())\n",
    "    # save watermarked image\n",
    "    if (i+1) in cfgs['save_iters']:\n",
    "        path = os.path.join(wm_path, f\"{imagename.split('.')[0]}_{i+1}.png\")\n",
    "        save_img(path, pred_img_tensor, pipe)\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7564e5fd-d5a3-4de6-a979-f649a2ed0650",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Postprocessing with Adaptive Enhancement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54bb397-633d-49a1-bfda-72b45e5373f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyperparameter\n",
    "ssim_threshold = cfgs['ssim_threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "97ba93ce-f400-4290-bfb5-bde57c96b990",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Original SSIM 0.6716844439506531\n"
     ]
    }
   ],
   "source": [
    "wm_img_path = os.path.join(wm_path, f\"{imagename.split('.')[0]}_{cfgs['save_iters'][-1]}.png\")\n",
    "wm_img_tensor = get_img_tensor(wm_img_path, device)\n",
    "ssim_value = ssim(wm_img_tensor, gt_img_tensor).item()\n",
    "logging.info(f'Original SSIM {ssim_value}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f43ec672-fa83-4b4a-9333-3d356798fced",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Optimal Theta 0.5625\n",
      "SSIM 0.9191962480545044, PSNR, 26.77979726207091, Detect Prob: 0.9999998430566757 after postprocessing\n"
     ]
    }
   ],
   "source": [
    "def binary_search_theta(threshold, lower=0., upper=1., precision=1e-6, max_iter=1000):\n",
    "    for i in range(max_iter):\n",
    "        mid_theta = (lower + upper) / 2\n",
    "        img_tensor = (gt_img_tensor-wm_img_tensor)*mid_theta+wm_img_tensor\n",
    "        ssim_value = ssim(img_tensor, gt_img_tensor).item()\n",
    "\n",
    "        if ssim_value <= threshold:\n",
    "            lower = mid_theta\n",
    "        else:\n",
    "            upper = mid_theta\n",
    "        if upper - lower < precision:\n",
    "            break\n",
    "    return lower\n",
    "\n",
    "optimal_theta = binary_search_theta(ssim_threshold, precision=0.01)\n",
    "logging.info(f'Optimal Theta {optimal_theta}')\n",
    "\n",
    "img_tensor = (gt_img_tensor-wm_img_tensor)*optimal_theta+wm_img_tensor\n",
    "\n",
    "ssim_value = ssim(img_tensor, gt_img_tensor).item()\n",
    "psnr_value = compute_psnr(img_tensor, gt_img_tensor)\n",
    "\n",
    "tester_prompt = '' \n",
    "text_embeddings = pipe.get_text_embedding(tester_prompt)\n",
    "det_prob = 1 - watermark_prob(img_tensor, pipe, wm_pipe, text_embeddings)\n",
    "\n",
    "path = os.path.join(wm_path, f\"{os.path.basename(wm_img_path).split('.')[0]}_SSIM{ssim_threshold}.png\")\n",
    "save_img(path, img_tensor, pipe)\n",
    "logging.info(f'SSIM {ssim_value}, PSNR, {psnr_value}, Detect Prob: {det_prob} after postprocessing')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36b8b169-c1e9-437e-b3db-4a46887046a9",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Attack Watermarked Image with Individual Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7294ec83-97cc-4806-8404-a4fc07d83f81",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===== Init Attackers =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "58f7c0c894e449a7bb96b24f437f5b07",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffuse attack initialized with noise step 60 and use prompt 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://compressai.s3.amazonaws.com/models/v1/cheng2020-anchor-3-e49be189.pth.tar\" to /home/xunaen/.cache/torch/hub/checkpoints/cheng2020-anchor-3-e49be189.pth.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec52604dac945eab78a394febbd6052",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/49.1M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://compressai.s3.amazonaws.com/models/v1/bmshj2018-factorized-prior-3-5c6f152b.pth.tar\" to /home/xunaen/.cache/torch/hub/checkpoints/bmshj2018-factorized-prior-3-5c6f152b.pth.tar\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62860dea346b47199900108e26bc3557",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/11.6M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from main.wmattacker import *\n",
    "from main.attdiffusion import ReSDPipeline\n",
    "\n",
    "logging.info(f'===== Init Attackers =====')\n",
    "att_pipe = ReSDPipeline.from_pretrained(\"/data/xunaen/Text-to-image-Copyright/stable-diffusion-1-5\", torch_dtype=torch.float16, revision=\"fp16\")\n",
    "att_pipe.set_progress_bar_config(disable=True)\n",
    "att_pipe.to(device)\n",
    "\n",
    "attackers = {\n",
    "    'diff_attacker_60': DiffWMAttacker(att_pipe, batch_size=5, noise_step=60, captions={}),\n",
    "    'cheng2020-anchor_3': VAEWMAttacker('cheng2020-anchor', quality=3, metric='mse', device=device),\n",
    "    'bmshj2018-factorized_3': VAEWMAttacker('bmshj2018-factorized', quality=3, metric='mse', device=device),\n",
    "    'jpeg_attacker_50': JPEGAttacker(quality=50),\n",
    "    'rotate_90': RotateAttacker(degree=90),\n",
    "    'brightness_0.5': BrightnessAttacker(brightness=0.5),\n",
    "    'contrast_0.5': ContrastAttacker(contrast=0.5),\n",
    "    'Gaussian_noise': GaussianNoiseAttacker(std=0.05),\n",
    "    'Gaussian_blur': GaussianBlurAttacker(kernel_size=5, sigma=1),\n",
    "    'bm3d': BM3DAttacker(),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051f3d2d-6946-4806-b0d8-6363d15c8fec",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.info(f'===== Start Attacking... =====')\n",
    "\n",
    "post_img = os.path.join(wm_path, f\"{imagename.split('.')[0]}_{cfgs['save_iters'][-1]}_SSIM{ssim_threshold}.png\")\n",
    "for attacker_name, attacker in attackers.items():\n",
    "    print(f'Attacking with {attacker_name}')\n",
    "    os.makedirs(os.path.join(wm_path, attacker_name), exist_ok=True)\n",
    "    att_img_path = os.path.join(wm_path, attacker_name, os.path.basename(post_img))\n",
    "    attackers[attacker_name].attack([post_img], [att_img_path])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a2b6fa-6b19-4918-a141-8a5b9d112f0a",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Attack Watermarked Image with Combined Attacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4b5ddabd-1d5f-4541-acc2-d42c2e3c5487",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===== Init Attackers =====\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e8627868f354fd888e0af432eb1924c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading pipeline components...:   0%|          | 0/7 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "ReSDPipeline {\n",
       "  \"_class_name\": \"ReSDPipeline\",\n",
       "  \"_diffusers_version\": \"0.21.4\",\n",
       "  \"_name_or_path\": \"/data/xunaen/Text-to-image-Copyright/stable-diffusion-1-5\",\n",
       "  \"feature_extractor\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPImageProcessor\"\n",
       "  ],\n",
       "  \"requires_safety_checker\": true,\n",
       "  \"safety_checker\": [\n",
       "    \"stable_diffusion\",\n",
       "    \"StableDiffusionSafetyChecker\"\n",
       "  ],\n",
       "  \"scheduler\": [\n",
       "    \"diffusers\",\n",
       "    \"PNDMScheduler\"\n",
       "  ],\n",
       "  \"text_encoder\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTextModel\"\n",
       "  ],\n",
       "  \"tokenizer\": [\n",
       "    \"transformers\",\n",
       "    \"CLIPTokenizer\"\n",
       "  ],\n",
       "  \"unet\": [\n",
       "    \"diffusers\",\n",
       "    \"UNet2DConditionModel\"\n",
       "  ],\n",
       "  \"vae\": [\n",
       "    \"diffusers\",\n",
       "    \"AutoencoderKL\"\n",
       "  ]\n",
       "}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from main.wmattacker import *\n",
    "from main.attdiffusion import ReSDPipeline\n",
    "\n",
    "case_list = ['w/ rot', 'w/o rot']\n",
    "\n",
    "logging.info(f'===== Init Attackers =====')\n",
    "att_pipe = ReSDPipeline.from_pretrained(\"/data/xunaen/Text-to-image-Copyright/stable-diffusion-1-5\", torch_dtype=torch.float16, revision=\"fp16\")\n",
    "att_pipe.set_progress_bar_config(disable=True)\n",
    "att_pipe.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb550932-cb3d-46fc-8174-c5ec2b69e447",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "post_img = os.path.join(wm_path, f\"{imagename.split('.')[0]}_{cfgs['save_iters'][-1]}_SSIM{ssim_threshold}.png\")\n",
    "\n",
    "for case in case_list:\n",
    "    print(f'Case: {case}')\n",
    "    if case == 'w/ rot':\n",
    "        attackers = {\n",
    "        'diff_attacker_60': DiffWMAttacker(att_pipe, batch_size=5, noise_step=60, captions={}),\n",
    "        'cheng2020-anchor_3': VAEWMAttacker('cheng2020-anchor', quality=3, metric='mse', device=device),\n",
    "        'bmshj2018-factorized_3': VAEWMAttacker('bmshj2018-factorized', quality=3, metric='mse', device=device),\n",
    "        'jpeg_attacker_50': JPEGAttacker(quality=50),\n",
    "        'rotate_90': RotateAttacker(degree=90),\n",
    "        'brightness_0.5': BrightnessAttacker(brightness=0.5),\n",
    "        'contrast_0.5': ContrastAttacker(contrast=0.5),\n",
    "        'Gaussian_noise': GaussianNoiseAttacker(std=0.05),\n",
    "        'Gaussian_blur': GaussianBlurAttacker(kernel_size=5, sigma=1),\n",
    "        'bm3d': BM3DAttacker(),\n",
    "        }\n",
    "        multi_name = 'all'\n",
    "    elif case == 'w/o rot':\n",
    "        attackers = {\n",
    "        'diff_attacker_60': DiffWMAttacker(att_pipe, batch_size=5, noise_step=60, captions={}),\n",
    "        'cheng2020-anchor_3': VAEWMAttacker('cheng2020-anchor', quality=3, metric='mse', device=device),\n",
    "        'bmshj2018-factorized_3': VAEWMAttacker('bmshj2018-factorized', quality=3, metric='mse', device=device),\n",
    "        'jpeg_attacker_50': JPEGAttacker(quality=50),\n",
    "        'brightness_0.5': BrightnessAttacker(brightness=0.5),\n",
    "        'contrast_0.5': ContrastAttacker(contrast=0.5),\n",
    "        'Gaussian_noise': GaussianNoiseAttacker(std=0.05),\n",
    "        'Gaussian_blur': GaussianBlurAttacker(kernel_size=5, sigma=1),\n",
    "        'bm3d': BM3DAttacker(),\n",
    "        }\n",
    "        multi_name = 'all_norot'\n",
    "        \n",
    "    \n",
    "    os.makedirs(os.path.join(wm_path, multi_name), exist_ok=True)\n",
    "    att_img_path = os.path.join(wm_path, multi_name, os.path.basename(post_img))\n",
    "    for i, (attacker_name, attacker) in enumerate(attackers.items()):\n",
    "        print(f'Attacking with {attacker_name}')\n",
    "        if i == 0:\n",
    "            attackers[attacker_name].attack([post_img], [att_img_path], multi=True)\n",
    "        else:\n",
    "            attackers[attacker_name].attack([att_img_path], [att_img_path], multi=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08da6ebe-ab6b-4ea0-9d55-006ace7bd4fd",
   "metadata": {},
   "source": [
    "## Detect Watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1f6064ad-8922-45f2-918d-8fc6157a5774",
   "metadata": {},
   "outputs": [],
   "source": [
    "post_img = os.path.join(wm_path, f\"{imagename.split('.')[0]}_{cfgs['save_iters'][-1]}_SSIM{ssim_threshold}.png\")\n",
    "\n",
    "attackers = ['diff_attacker_60', 'cheng2020-anchor_3', 'bmshj2018-factorized_3', 'jpeg_attacker_50', \n",
    "             'brightness_0.5', 'contrast_0.5', 'Gaussian_noise', 'Gaussian_blur', 'rotate_90', 'bm3d', \n",
    "             'all', 'all_norot']\n",
    "\n",
    "tester_prompt = '' # assume at the detection time, the original prompt is unknown\n",
    "text_embeddings = pipe.get_text_embedding(tester_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4018ca81-ba9a-46d0-bad1-921132265b83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===== Testing the Watermarked Images ./example/output/pepper_100_SSIM0.92.png =====\n",
      "Watermark Presence Prob.: 0.9999998369733066\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'===== Testing the Watermarked Images {post_img} =====')\n",
    "det_prob = 1 - watermark_prob(post_img, pipe, wm_pipe, text_embeddings)\n",
    "logging.info(f'Watermark Presence Prob.: {det_prob}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5edeed73-b921-46b4-8bca-aeb436fdc843",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "===== Testing the Attacked Watermarked Images =====\n",
      "=== Attacker Name: diff_attacker_60 ===\n",
      "Watermark Presence Prob.: 0.9931504475822778\n",
      "=== Attacker Name: cheng2020-anchor_3 ===\n",
      "Watermark Presence Prob.: 0.9998271427823526\n",
      "=== Attacker Name: bmshj2018-factorized_3 ===\n",
      "Watermark Presence Prob.: 0.9999675261060684\n",
      "=== Attacker Name: jpeg_attacker_50 ===\n",
      "Watermark Presence Prob.: 0.9999992282329905\n",
      "=== Attacker Name: brightness_0.5 ===\n",
      "Watermark Presence Prob.: 0.9999999282904217\n",
      "=== Attacker Name: contrast_0.5 ===\n",
      "Watermark Presence Prob.: 0.9999999981334986\n",
      "=== Attacker Name: Gaussian_noise ===\n",
      "Watermark Presence Prob.: 0.9999546373440696\n",
      "=== Attacker Name: Gaussian_blur ===\n",
      "Watermark Presence Prob.: 0.9999999332021414\n",
      "=== Attacker Name: rotate_90 ===\n",
      "Watermark Presence Prob.: 0.9651175033287247\n",
      "=== Attacker Name: bm3d ===\n",
      "Watermark Presence Prob.: 0.9999988571273855\n",
      "=== Attacker Name: all ===\n",
      "Watermark Presence Prob.: 0.5464426447483964\n",
      "=== Attacker Name: all_norot ===\n",
      "Watermark Presence Prob.: 0.9916322084475203\n"
     ]
    }
   ],
   "source": [
    "logging.info(f'===== Testing the Attacked Watermarked Images =====')\n",
    "for attacker_name in attackers:\n",
    "    if not os.path.exists(os.path.join(wm_path, attacker_name)):\n",
    "        logging.info(f'Attacked images under {attacker_name} not exist.')\n",
    "        continue\n",
    "        \n",
    "    logging.info(f'=== Attacker Name: {attacker_name} ===')\n",
    "    det_prob = 1 - watermark_prob(os.path.join(wm_path, attacker_name, os.path.basename(post_img)), pipe, wm_pipe, text_embeddings)\n",
    "    logging.info(f'Watermark Presence Prob.: {det_prob}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
